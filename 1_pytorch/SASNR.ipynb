{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96811fb-a66f-45fd-b50d-0804cd287d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7164, 0.7461, 0.7467],\n",
      "        [0.7423, 0.7301, 0.7510]]) torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3, 2048])\n",
      "torch.Size([2, 3, 2048])\n",
      "torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3])\n",
      "tensor(-0.9634)\n",
      "tensor([[0.6828, 0.6809, 0.6882],\n",
      "        [0.6854, 0.6885, 0.6849]]) torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3, 2048])\n",
      "torch.Size([2, 3, 2048])\n",
      "torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3])\n",
      "tensor(-10.7479)\n",
      "tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000]]) torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3, 2048])\n",
      "torch.Size([2, 3, 2048])\n",
      "torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3]) torch.Size([2, 3])\n",
      "tensor(-140.8473)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "EPS = 1e-13\n",
    "\n",
    "class SASNRLossSegment(nn.Module):\n",
    "    def __init__(self, reduction=torch.mean):\n",
    "        super(SASNRLossSegment, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target, out_dict=True):\n",
    "\n",
    "        # (12)\n",
    "        denom_s = torch.sum(output*target,dim=-1)\n",
    "        numer_s = torch.norm(target, dim=-1) * torch.norm(target, dim=-1)\n",
    "        #scale = (numer_s/denom_s)\n",
    "        scale = denom_s/numer_s\n",
    "        s_target = torch.unsqueeze(scale,-1) * target\n",
    "        print(f\"{scale} {numer_s.shape} {denom_s.shape} {s_target.shape}\")\n",
    "\n",
    "        # (13)\n",
    "        e_noise = output - s_target\n",
    "        print(f\"{e_noise.shape}\")\n",
    " \n",
    "        (14)\n",
    "        # Compute norms\n",
    "        norm_s_target_squared = torch.sum(s_target ** 2, dim=-1)  \n",
    "        norm_e_noise_squared = torch.sum(e_noise ** 2, dim=-1)  \n",
    "        norm_predicted = torch.norm(output, dim=-1)  \n",
    "        norm_target = torch.norm(target, dim=-1) \n",
    "\n",
    "        print(f\"{norm_s_target_squared.shape} {norm_e_noise_squared.shape} {norm_predicted.shape} {norm_target.shape}\")\n",
    "\n",
    "        # Scaling factors\n",
    "        scaling_factor = norm_predicted / norm_target\n",
    "        min_factor = torch.minimum(scaling_factor, torch.ones_like(scaling_factor))\n",
    "        max_factor = torch.maximum(scaling_factor, torch.ones_like(scaling_factor))\n",
    "        scale_term = min_factor / max_factor\n",
    "\n",
    "\n",
    "        # Compute SA-SNR loss\n",
    "        ratio = norm_s_target_squared / (norm_e_noise_squared + EPS)  \n",
    "        loss_per_element = -10 * torch.log10(ratio * scale_term + EPS)  \n",
    "\n",
    "        loss = self.reduction(loss_per_element)\n",
    "        return {\"SASNRLossSegment\": loss} if out_dict else loss\n",
    "\n",
    "x = torch.rand(2,3,2048)\n",
    "y = torch.rand(2,3,2048)\n",
    "\n",
    "m = SASNRLossSegment()\n",
    "\n",
    "\n",
    "l = m(x,y,out_dict=False)\n",
    "print(l)\n",
    "\n",
    "y = x+0.5* torch.rand(2,3,2048)\n",
    "l = m(x,y,out_dict=False)\n",
    "print(l)\n",
    "\n",
    "y = x\n",
    "l = m(x,y,out_dict=False)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387b5aeb-54b4-411d-98ed-d74c56cc25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[498.7735, 517.9832, 514.9672],\n",
      "        [518.9438, 517.7992, 507.6986]]) tensor([[665.8411, 684.2076, 679.7012],\n",
      "        [685.8348, 688.7520, 675.1812]]) tensor([[0.7491, 0.7571, 0.7576],\n",
      "        [0.7567, 0.7518, 0.7519]])\n",
      "{'CosSDRLossSegment': tensor(-0.7540)}\n",
      "tensor([[674.1790, 678.7164, 677.8181],\n",
      "        [701.0212, 691.0522, 677.8785]]) tensor([[674.1791, 678.7162, 677.8181],\n",
      "        [701.0211, 691.0522, 677.8785]]) tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000]])\n",
      "{'CosSDRLossSegment': tensor(-1.)}\n"
     ]
    }
   ],
   "source": [
    "class CosSDRLossSegment(nn.Module):\n",
    "    \"\"\"\n",
    "    It's a cosine similarity between predicted and clean signal\n",
    "        loss = - <y_true, y_pred> / (||y_true|| * ||y_pred||)\n",
    "    This loss function is always bounded between -1 and 1\n",
    "    Ref: https://openreview.net/pdf?id=SkeRTsAcYm\n",
    "    Hyeong-Seok Choi et al., Phase-aware Speech Enhancement with Deep Complex U-Net,\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction=torch.mean):\n",
    "        super(CosSDRLossSegment, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target, out_dict=True):\n",
    "        num = torch.sum(target * output, dim=-1)\n",
    "        den = torch.norm(target, dim=-1) * torch.norm(output, dim=-1)\n",
    "        print(f\"{num} {den} {num/den}\")\n",
    "        loss_per_element = -num / (den + EPS)\n",
    "        loss = self.reduction(loss_per_element)\n",
    "        return {\"CosSDRLossSegment\": loss} if out_dict else loss\n",
    "x = torch.rand(2,3,2048)\n",
    "y = torch.rand(2,3,2048)\n",
    "\n",
    "m = CosSDRLossSegment()\n",
    "\n",
    "z = m(x,y)\n",
    "print(z)\n",
    "\n",
    "y = x\n",
    "z = m(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947bfb7-6347-408c-bc2a-2e76c14ddbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
