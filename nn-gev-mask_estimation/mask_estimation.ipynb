{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479a6f07-928b-4ace-a1c7-958a1ecc6a41",
   "metadata": {},
   "source": [
    "https://github.com/fgnt/nn-gev/blob/master/fgnt/mask_estimation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b16404-3c64-4f3e-9bf3-51eac6963152",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82cb7123-464b-47d0-b460-301c8944e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _voiced_unvoiced_split_characteristic(number_of_frequency_bins):\n",
    "    split_bin = 200\n",
    "    transition_width = 99\n",
    "    fast_transition_width = 5\n",
    "    low_bin = 4\n",
    "    high_bin = 500\n",
    "\n",
    "    a = np.arange(0, transition_width)\n",
    "    a = np.pi / (transition_width - 1) * a\n",
    "    transition = 0.5 * (1 + np.cos(a))\n",
    "\n",
    "    b = np.arange(0, fast_transition_width)\n",
    "    b = np.pi / (fast_transition_width - 1) * b\n",
    "    fast_transition = (np.cos(b) + 1) / 2\n",
    "\n",
    "    transition_voiced_start = int(split_bin - transition_width / 2)\n",
    "    voiced = np.ones(number_of_frequency_bins)\n",
    "\n",
    "    # High Edge\n",
    "    voiced[transition_voiced_start - 1: (\n",
    "        transition_voiced_start + transition_width - 1)] = transition\n",
    "    voiced[transition_voiced_start - 1 + transition_width: len(voiced)] = 0\n",
    "\n",
    "    # Low Edge\n",
    "    voiced[0: low_bin] = 0\n",
    "    voiced[low_bin - 1: (low_bin + fast_transition_width - 1)] = \\\n",
    "        1 - fast_transition\n",
    "\n",
    "    # Low Edge\n",
    "    unvoiced = np.ones(number_of_frequency_bins)\n",
    "    unvoiced[transition_voiced_start - 1: (\n",
    "        transition_voiced_start + transition_width - 1)] = 1 - transition\n",
    "    unvoiced[0: (transition_voiced_start)] = 0\n",
    "\n",
    "    # High Edge\n",
    "    unvoiced[high_bin - 1: (len(unvoiced))] = 0\n",
    "    unvoiced[\n",
    "    high_bin - 1: (high_bin + fast_transition_width - 1)] = fast_transition\n",
    "\n",
    "    return (voiced, unvoiced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b78697-5b8f-46f8-adee-70693b61068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_IBM(X, N,\n",
    "                 threshold_unvoiced_speech=5,\n",
    "                 threshold_voiced_speech=0,\n",
    "                 threshold_unvoiced_noise=-10,\n",
    "                 threshold_voiced_noise=-10,\n",
    "                 low_cut=5,\n",
    "                 high_cut=500):\n",
    "    \"\"\"Estimate an ideal binary mask given the speech and noise spectrum.\n",
    "    :param X: speech signal in STFT domain with shape (frames, frequency-bins)\n",
    "    :param N: noise signal in STFT domain with shape (frames, frequency-bins)\n",
    "    :param threshold_unvoiced_speech:\n",
    "    :param threshold_voiced_speech:\n",
    "    :param threshold_unvoiced_noise:\n",
    "    :param threshold_voiced_noise:\n",
    "    :param low_cut: all values with frequency<low_cut are set to 0 in the\n",
    "        speech mask ans set to 1 in the noise mask\n",
    "    :param high_cut: all values with frequency>high_cut are set to 0 in the\n",
    "        speech mask ans set to 1 in the noise mask\n",
    "    :return: (speech mask, noise mask): tuple containing the two arrays,\n",
    "        which are the masks for X and N\n",
    "    \"\"\"\n",
    "    (voiced, unvoiced) = _voiced_unvoiced_split_characteristic(X.shape[-1])\n",
    "\n",
    "    # calculate the thresholds\n",
    "    threshold = threshold_voiced_speech * voiced + \\\n",
    "                threshold_unvoiced_speech * unvoiced\n",
    "    threshold_new = threshold_unvoiced_noise * voiced + \\\n",
    "                    threshold_voiced_noise * unvoiced\n",
    "\n",
    "    xPSD = X * X.conjugate()  # |X|^2 = Power-Spectral-Density\n",
    "\n",
    "    # each frequency is multiplied with another threshold\n",
    "    c = np.power(10, (threshold / 10))\n",
    "    xPSD_threshold = xPSD / c\n",
    "    c_new = np.power(10, (threshold_new / 10))\n",
    "    xPSD_threshold_new = xPSD / c_new\n",
    "\n",
    "    nPSD = N * N.conjugate()\n",
    "\n",
    "    speechMask = (xPSD_threshold > nPSD)\n",
    "\n",
    "    speechMask = np.logical_and(speechMask, (xPSD_threshold > 0.005))\n",
    "    speechMask[..., 0:low_cut - 1] = 0\n",
    "    speechMask[..., high_cut:len(speechMask[0])] = 0\n",
    "\n",
    "    noiseMask = (xPSD_threshold_new < nPSD)\n",
    "\n",
    "    noiseMask = np.logical_or(noiseMask, (xPSD_threshold_new < 0.005))\n",
    "    noiseMask[..., 0: low_cut - 1] = 1\n",
    "    noiseMask[..., high_cut: len(noiseMask[0])] = 1\n",
    "\n",
    "    return (speechMask, noiseMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a9946-883a-484d-b608-3063d6756793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
