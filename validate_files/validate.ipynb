{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/nas/DB/[DB]_IITP/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speeches with missing channel 1 is 0\n",
      "speeches with missing channel 2 is 207\n",
      "speeches with missing channel 3 is 1233\n",
      "speeches with missing channel 4 is 151\n",
      "speeches with missing channel 5 is 0\n",
      "speeches with missing channel 6 is 0\n",
      "speeches with missing channel 7 is 0\n",
      "speeches with missing channel 8 is 26\n",
      "speeches with missing channel 9 is 59\n",
      "speeches with missing channel 10 is 0\n",
      "speeches with missing channel 11 is 0\n",
      "speeches with missing channel 12 is 0\n",
      "speeches with missing channel 13 is 0\n",
      "speeches with missing channel 14 is 0\n",
      "speeches with missing channel 15 is 0\n",
      "speeches with missing channel 16 is 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "file = open('train.txt')\n",
    "list = file.read()\n",
    "file.close()\n",
    "test_cnt = 0\n",
    "target = list.split('\\n')\n",
    "total=0\n",
    "dict = {}\n",
    "# mapping\n",
    "for i in target :\n",
    "    #print(i)\n",
    "    if i == '' :\n",
    "        break\n",
    "    a =  i.split('.')\n",
    "    a = a[0]\n",
    "    b = a.split('_')\n",
    "    c = b[3].split('-')\n",
    "    id = b[1]+'_'+b[2]+'-'+c[1]\n",
    "    ch = c[0]\n",
    "    \n",
    "    if id not in dict :\n",
    "        dict[id] = [ch]\n",
    "    else :\n",
    "        dict[id].append(ch)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "output = open('output.txt','w')\n",
    "\n",
    "missing = np.zeros(16)\n",
    "\n",
    "# validate\n",
    "for i in dict :\n",
    "    if len(dict[i]) != 16 : \n",
    "        missing[16-len(dict[i])] = missing[16-len(dict[i])]+1 \n",
    "        cnt=cnt+1\n",
    "        output.write(i + ' has ' + str(len(dict[i])) + ' channels'+ '\\n')\n",
    "        check = np.ones(16)\n",
    "        for j in dict[i] : \n",
    "            check[int(j)-1]=0\n",
    "        idx = 1    \n",
    "        for j in check :\n",
    "            idx=idx+1\n",
    "            if j == 1 :\n",
    "                total=total+1\n",
    "                output.write(str(idx)+ '\\n')\n",
    "output.write( 'total '+str(total)+' files are missing'+ '\\n')\n",
    "output.write(str((cnt/len(dict))*100)+'%('+str(cnt)+') of data(total '+str(len(dict))+') are invalid'+ '\\n')\n",
    "for i in range(16) :\n",
    "    output.write(\"speeches with missing channel \"+str(i+1) + \" is \" + str(int(missing[i])))\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('eval.txt')\n",
    "list = file.read()\n",
    "file.close()\n",
    "test_cnt = 0\n",
    "target = list.split('\\n')\n",
    "\n",
    "total=0\n",
    "dict = {}\n",
    "# mapping\n",
    "for i in target :\n",
    "    #print(i)\n",
    "    if i == '' :\n",
    "        break\n",
    "    a =  i.split('.')\n",
    "    a = a[0]\n",
    "    b = a.split('_')\n",
    "    c = b[5].split('-')\n",
    "    id = b[0]+'_'+b[1]+'_'+b[2]+'_'+b[3]+'_'+b[4]+'-'+c[1]\n",
    "    ch = c[0]\n",
    "    \n",
    "    if id not in dict :\n",
    "        dict[id] = [ch]\n",
    "    else :\n",
    "        dict[id].append(ch)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "output = open('output_eval.txt','w')\n",
    "\n",
    "missing = np.zeros(16)\n",
    "# validate\n",
    "for i in dict :\n",
    "    if len(dict[i]) != 16 : \n",
    "        cnt=cnt+1\n",
    "        output.write(i + ' has ' + str(len(dict[i])) + ' channels'+ '\\n')\n",
    "        check = np.ones(16)\n",
    "        for j in dict[i] : \n",
    "            check[int(j)-1]=0\n",
    "        idx = 1    \n",
    "        for j in check :\n",
    "            idx=idx+1\n",
    "            if j == 1 :\n",
    "                total=total+1\n",
    "                output.write(str(idx)+ '\\n')\n",
    "output.write( 'total '+str(total)+' files are missing'+ '\\n')\n",
    "output.write(str((cnt/len(dict))*100)+'%('+str(cnt)+') of data(total '+str(len(dict))+') are invalid'+ '\\n')\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
